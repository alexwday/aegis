# ============================================
# LOGGING CONFIGURATION
# ============================================
LOG_LEVEL=INFO  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL

# ============================================
# CONVERSATION CONFIGURATION
# ============================================
INCLUDE_SYSTEM_MESSAGES=false  # Whether to keep system role messages
ALLOWED_ROLES=user,assistant  # Comma-separated list of roles to keep
MAX_HISTORY_LENGTH=10  # Maximum number of messages to keep

# ============================================
# LLM CONFIGURATION
# ============================================
AUTH_METHOD=api_key  # Authentication method: "oauth" or "api_key"
API_KEY=your_api_key_here  # Direct API key for LLM (used when AUTH_METHOD=api_key)

# ============================================
# LLM CONFIGURATION
# ============================================
# Base URL for OpenAI API (use https://api.openai.com/v1 for OpenAI, or custom endpoint for private deployments)
LLM_BASE_URL=https://api.openai.com/v1

# Small Model - Fast, efficient for simple tasks
LLM_MODEL_SMALL=gpt-4.1-nano-2025-04-14
LLM_TEMPERATURE_SMALL=0.3  # Lower temperature for more consistent outputs
LLM_MAX_TOKENS_SMALL=1000  # Shorter responses for simple tasks
LLM_TIMEOUT_SMALL=30  # 30 second timeout
LLM_MAX_RETRIES_SMALL=3
LLM_COST_INPUT_SMALL=0.0001  # Cost per 1K input tokens in USD
LLM_COST_OUTPUT_SMALL=0.0002  # Cost per 1K output tokens in USD

# Medium Model - Balanced performance for most tasks
LLM_MODEL_MEDIUM=gpt-4.1-mini-2025-04-14
LLM_TEMPERATURE_MEDIUM=0.5  # Balanced temperature
LLM_MAX_TOKENS_MEDIUM=2000  # Medium length responses
LLM_TIMEOUT_MEDIUM=60  # 60 second timeout
LLM_MAX_RETRIES_MEDIUM=3
LLM_COST_INPUT_MEDIUM=0.0003  # Cost per 1K input tokens in USD
LLM_COST_OUTPUT_MEDIUM=0.0006  # Cost per 1K output tokens in USD

# Large Model - Most capable for complex reasoning
LLM_MODEL_LARGE=gpt-4.1-2025-04-14
LLM_TEMPERATURE_LARGE=0.7  # Higher temperature for creative tasks
LLM_MAX_TOKENS_LARGE=4000  # Longer responses for complex tasks
LLM_TIMEOUT_LARGE=120  # 2 minute timeout
LLM_MAX_RETRIES_LARGE=3
LLM_COST_INPUT_LARGE=0.0010  # Cost per 1K input tokens in USD
LLM_COST_OUTPUT_LARGE=0.0020  # Cost per 1K output tokens in USD

# Embedding Model - For vector representations
LLM_EMBEDDING_MODEL=text-embedding-3-large
LLM_EMBEDDING_DIMENSIONS=3072  # Dimensions for text-embedding-3-large (256, 1024, or 3072)
LLM_EMBEDDING_TIMEOUT=30  # 30 second timeout
LLM_EMBEDDING_MAX_RETRIES=3
LLM_EMBEDDING_COST_INPUT=0.00002  # Cost per 1K input tokens in USD (embeddings only have input cost)

# ============================================
# DATABASE CONFIGURATION
# ============================================
POSTGRES_HOST=localhost  # Database host
POSTGRES_PORT=5432  # Database port
POSTGRES_DATABASE=your_database_name  # Database name
POSTGRES_USER=your_database_user  # Database user
POSTGRES_PASSWORD=your_database_password  # Database password

# ============================================
# OAUTH CONFIGURATION
# ============================================
OAUTH_ENDPOINT=https://api.example.com/oauth/token  # OAuth token endpoint URL (used when AUTH_METHOD=oauth)
OAUTH_CLIENT_ID=your_client_id_here  # OAuth client ID (used when AUTH_METHOD=oauth)
OAUTH_CLIENT_SECRET=your_client_secret_here  # OAuth client secret (used when AUTH_METHOD=oauth)
OAUTH_GRANT_TYPE=client_credentials  # OAuth grant type (typically client_credentials)
OAUTH_MAX_RETRIES=3  # Maximum number of retry attempts for token generation
OAUTH_RETRY_DELAY=1  # Initial delay in seconds between retries (exponential backoff)

# ============================================
# SSL CONFIGURATION
# ============================================
SSL_VERIFY=false  # Whether to verify SSL certificates (true/false)
SSL_CERT_PATH=src/aegis/utils/ssl/rbc-ca-bundle.cer  # Path to .cer file for SSL verification (required if SSL_VERIFY=true)

# ============================================
# ENVIRONMENT CONFIGURATION
# ============================================
# Environment (local, dev, sai, or prod)
ENVIRONMENT=local